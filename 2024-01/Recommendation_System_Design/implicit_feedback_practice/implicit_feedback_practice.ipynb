{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting implicit\n",
      "  Downloading implicit-0.7.2.tar.gz (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy>=1.17.0 (from implicit)\n",
      "  Obtaining dependency information for numpy>=1.17.0 from https://files.pythonhosted.org/packages/75/5b/ca6c8bd14007e5ca171c7c03102d17b4f4e0ceb53957e8c44343a9546dcc/numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata\n",
      "  Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting scipy>=0.16 (from implicit)\n",
      "  Obtaining dependency information for scipy>=0.16 from https://files.pythonhosted.org/packages/a1/72/8d2b7815d754e52b31ebcacf93111581f6948d96910a1a665b8cefc5cfe1/scipy-1.13.0-cp312-cp312-macosx_12_0_arm64.whl.metadata\n",
      "  Using cached scipy-1.13.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "Collecting tqdm>=4.27 (from implicit)\n",
      "  Obtaining dependency information for tqdm>=4.27 from https://files.pythonhosted.org/packages/2a/14/e75e52d521442e2fcc9f1df3c5e456aead034203d4797867980de558ab34/tqdm-4.66.2-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl (from implicit)\n",
      "  Obtaining dependency information for threadpoolctl from https://files.pythonhosted.org/packages/1e/84/ccd9b08653022b7785b6e3ee070ffb2825841e0dc119be22f0840b2b35cb/threadpoolctl-3.4.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.4.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "Using cached scipy-1.13.0-cp312-cp312-macosx_12_0_arm64.whl (30.4 MB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached threadpoolctl-3.4.0-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: implicit\n",
      "  Building wheel for implicit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for implicit: filename=implicit-0.7.2-cp312-cp312-macosx_13_0_arm64.whl size=752647 sha256=7db083d69e1ba4914e591fe47b942ddbaa0d9f6937768a7b0edc4832fde57e05\n",
      "  Stored in directory: /Users/ull/Library/Caches/pip/wheels/b2/00/4f/9ff8af07a0a53ac6007ea5d739da19cfe147a2df542b6899f8\n",
      "Successfully built implicit\n",
      "Installing collected packages: tqdm, threadpoolctl, numpy, scipy, implicit\n",
      "Successfully installed implicit-0.7.2 numpy-1.26.4 scipy-1.13.0 threadpoolctl-3.4.0 tqdm-4.66.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-03 13:36:10--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: ‘ml-latest-small.zip’\n",
      "\n",
      "ml-latest-small.zip 100%[===================>] 955.28K   840KB/s    in 1.1s    \n",
      "\n",
      "2024-04-03 13:36:13 (840 KB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
      "\n",
      "Archive:  ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/tags.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/movies.csv  \n"
     ]
    }
   ],
   "source": [
    "# !wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "# !unzip ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating,timestamp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "with open(\"ml-latest-small/ratings.csv\", \"r\") as f:\n",
    "    print(f.readline())\n",
    "\n",
    "    rows = []\n",
    "    cols = []\n",
    "    data = []\n",
    "\n",
    "    for line in f:\n",
    "        uid, mid, _, _ = line.split(\",\")\n",
    "        rows.append(int(uid))\n",
    "        cols.append(int(mid))\n",
    "        data.append(1)\n",
    "\n",
    "rows = np.array(rows)\n",
    "cols = np.array(cols)\n",
    "data = np.array(data)\n",
    "\n",
    "### make the csr data\n",
    "ratings_csr = csr_matrix( (data, (rows, cols)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 51.55it/s, train_auc=90.30%, skipped=24.87%]\n"
     ]
    }
   ],
   "source": [
    "from implicit import bpr\n",
    "\n",
    "# factors default = 100\n",
    "# 이로인해 오래걸리기 때문에 현재는 10으로 설정\n",
    "model = bpr.BayesianPersonalizedRanking(factors = 10)\n",
    "model.fit(ratings_csr)\n",
    "\n",
    "# train_auc -> train data set에서 잘 맞추는 정도?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[122904 134130 112556 112852  84152 139385 109374  80463  69122  89745]\n",
      " [  3061   2352   1414   1269   1238   4713   2971   3404   1019   2901]]\n",
      "[[3.8175251 3.6596115 3.601283  3.534018  3.4999392 3.4010913 3.3381462\n",
      "  3.3298419 3.3270571 3.3151565]\n",
      " [2.2930713 2.262011  2.2375998 2.2236404 2.2204537 2.2015321 2.2008445\n",
      "  2.1898289 2.1729798 2.1535513]]\n"
     ]
    }
   ],
   "source": [
    "users = [2, 3]\n",
    "ids, scores = model.recommend(users, ratings_csr[users])\n",
    "print(ids) # 유저에게 추천하는 아이템의 이름\n",
    "print(scores) # 내부적으로 정해진 추천 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.12280127 -0.8148106  -0.3037428  ... -1.3468064   1.4359229\n",
      "   1.        ]\n",
      " [-0.89448166 -0.04790242  0.30201313 ...  0.816144   -0.44200027\n",
      "   1.        ]\n",
      " ...\n",
      " [-0.54553807  1.1838983  -0.32357582 ... -0.60850435  2.4432578\n",
      "   1.        ]\n",
      " [ 0.18648137 -0.16681994 -0.32527804 ... -0.35707948  0.02169952\n",
      "   1.        ]\n",
      " [-2.164012   -0.15486223 -0.2135257  ...  0.722474   -0.9217359\n",
      "   1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(611, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.user_factors)\n",
    "# user 수만큼 벡터가 존재한다.\n",
    "model.user_factors.shape\n",
    "# factors의 마지막 값을 바이오스로 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/4a/0e/e4e033371a7cba9da0db5ccb507a9174e41b9c29189a932d01f2f61ecfc0/torch-2.2.2-cp312-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torch-2.2.2-cp312-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/8b/69/acdf492db27dea7be5c63053230130e0574fd8a376de3555d5f8bbc3d3ad/filelock-3.13.3-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Obtaining dependency information for sympy from https://files.pythonhosted.org/packages/d2/05/e6600db80270777c4a64238a98d442f0fd07cc8915be2a1c16da7f2b9e74/sympy-1.12-py3-none-any.whl.metadata\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/d5/f0/8fbc882ca80cf077f1b246c0e3c3465f7f415439bdea6b899f6b19f61f70/networkx-3.2.1-py3-none-any.whl.metadata\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Obtaining dependency information for jinja2 from https://files.pythonhosted.org/packages/30/6d/6de6be2d02603ab56e72997708809e8a5b0fbfee080735109b40a3564843/Jinja2-3.1.3-py3-none-any.whl.metadata\n",
      "  Using cached Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/93/6d/66d48b03460768f523da62a57a7e14e5e95fdf339d79e996ce3cecda2cdb/fsspec-2024.3.1-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/53/bd/583bf3e4c8d6a321938c13f49d44024dbe5ed63e0a7ba127e454a66da974/MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Obtaining dependency information for mpmath>=0.19 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.2.2-cp312-none-macosx_11_0_arm64.whl (59.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Downloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.3 fsspec-2024.3.1 jinja2-3.1.3 mpmath-1.3.0 networkx-3.2.1 sympy-1.12 torch-2.2.2 typing-extensions-4.10.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch를 이용하여 fit을 직접 구현하기\n",
    "\n",
    "import torch\n",
    "\n",
    "users = torch.from_numpy(rows)\n",
    "items = torch.from_numpy(cols)\n",
    "\n",
    "# 각 요소의 갯수를 지정한다.\n",
    "n_factors = 10\n",
    "n_items = max(items) + 1\n",
    "n_users = max(users) + 1\n",
    "\n",
    "# 각 아이템마다 10차원짜리 factor를 생성한다.\n",
    "item_bias = torch.randn(n_items, requires_grad=True)\n",
    "item_factor = torch.randn(n_items, n_factors, requires_grad=True)\n",
    "user_factor = torch.randn(n_users, n_factors, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train acc: 0.8614383935928345\n",
      "epoch: 1, train acc: 0.9040421843528748\n",
      "epoch: 2, train acc: 0.9384446144104004\n",
      "epoch: 3, train acc: 0.9613332748413086\n",
      "epoch: 4, train acc: 0.9746122360229492\n",
      "epoch: 5, train acc: 0.9830517172813416\n",
      "epoch: 6, train acc: 0.9877027869224548\n",
      "epoch: 7, train acc: 0.9902812242507935\n",
      "epoch: 8, train acc: 0.9916993975639343\n",
      "epoch: 9, train acc: 0.9924332499504089\n",
      "epoch: 10, train acc: 0.9931274652481079\n",
      "epoch: 11, train acc: 0.9933555722236633\n",
      "epoch: 12, train acc: 0.9933158755302429\n",
      "epoch: 13, train acc: 0.9938910603523254\n",
      "epoch: 14, train acc: 0.9937323927879333\n",
      "epoch: 15, train acc: 0.9934646487236023\n",
      "epoch: 16, train acc: 0.993365466594696\n",
      "epoch: 17, train acc: 0.9937224984169006\n",
      "epoch: 18, train acc: 0.9938216805458069\n",
      "epoch: 19, train acc: 0.9939208030700684\n",
      "epoch: 20, train acc: 0.9933357238769531\n",
      "epoch: 21, train acc: 0.9938712120056152\n",
      "epoch: 22, train acc: 0.9934844970703125\n",
      "epoch: 23, train acc: 0.9937819838523865\n",
      "epoch: 24, train acc: 0.9942679405212402\n",
      "epoch: 25, train acc: 0.9937621355056763\n",
      "epoch: 26, train acc: 0.9938514232635498\n",
      "epoch: 27, train acc: 0.9935042858123779\n",
      "epoch: 28, train acc: 0.9940100908279419\n",
      "epoch: 29, train acc: 0.9940299391746521\n",
      "epoch: 30, train acc: 0.9939604997634888\n",
      "epoch: 31, train acc: 0.9942877292633057\n",
      "epoch: 32, train acc: 0.99424809217453\n",
      "epoch: 33, train acc: 0.9938414692878723\n",
      "epoch: 34, train acc: 0.9943075776100159\n",
      "epoch: 35, train acc: 0.9938712120056152\n",
      "epoch: 36, train acc: 0.9940299391746521\n",
      "epoch: 37, train acc: 0.9939208030700684\n",
      "epoch: 38, train acc: 0.9943670630455017\n",
      "epoch: 39, train acc: 0.9941290616989136\n",
      "epoch: 40, train acc: 0.9941191673278809\n",
      "epoch: 41, train acc: 0.9944464564323425\n",
      "epoch: 42, train acc: 0.9938117265701294\n",
      "epoch: 43, train acc: 0.9942282438278198\n",
      "epoch: 44, train acc: 0.994436502456665\n",
      "epoch: 45, train acc: 0.9945654273033142\n",
      "epoch: 46, train acc: 0.9947142004966736\n",
      "epoch: 47, train acc: 0.9949720501899719\n",
      "epoch: 48, train acc: 0.9943175315856934\n",
      "epoch: 49, train acc: 0.994436502456665\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adam([item_bias, item_factor, user_factor], lr=0.1)\n",
    "logsigmoid = torch.nn.LogSigmoid()\n",
    "lmd = 0.01\n",
    "\n",
    "for epoch in range(50):\n",
    "\n",
    "    neg_items = torch.randint(1, n_items, (len(items), ))\n",
    "\n",
    "    pos_pref = item_bias[items] + (user_factor[users] * item_factor[items]).sum(dim=1)\n",
    "    neg_pref = item_bias[neg_items] + (user_factor[users] * item_factor[neg_items]).sum(dim=1)\n",
    "    reg = (item_bias ** 2).sum() + (user_factor ** 2).sum() + (item_factor ** 2).sum()\n",
    "\n",
    "    # object_function = logsigmoid(pos_pref - neg_pref).sum() - lmd * reg\n",
    "    cost = -logsigmoid(pos_pref - neg_pref).sum() + lmd * reg\n",
    "\n",
    "    optim.zero_grad()\n",
    "    cost.backward()\n",
    "    optim.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 맞춘 애들의 개수 / \n",
    "        train_acc = (pos_pref > neg_pref).sum() / len(pos_pref)\n",
    "        print(f\"epoch: {epoch}, train acc: {train_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139385 122918 122920   1375 159093  79592  55765   4971   4963   4262]\n",
      "[16.516188  15.695243  15.158437  14.920969  14.626219  14.591423\n",
      " 14.513702  14.4249935 14.378375  14.219963 ]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "   \n",
    "    n_outputs = 10\n",
    "    uid = 2\n",
    "    \n",
    "    scores_all = item_bias + (user_factor[uid] * item_factor).sum(dim=1) \n",
    "    scores_all = scores_all.numpy()\n",
    "    \n",
    "    ids = np.argsort(scores_all)[::-1]\n",
    "    pure_ids = ids[np.isin(ids, items[users == uid], invert=True)]\n",
    "    \n",
    "    pure_ids = pure_ids[:n_outputs]\n",
    "    scores = scores_all[pure_ids]\n",
    "   \n",
    "    print(pure_ids)\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
