{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting implicit\n",
      "  Downloading implicit-0.7.2-cp39-cp39-macosx_11_0_arm64.whl (765 kB)\n",
      "\u001b[K     |████████████████████████████████| 765 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl in /Users/ull/Library/Python/3.9/lib/python/site-packages (from implicit) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/ull/Library/Python/3.9/lib/python/site-packages (from implicit) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.16 in /Users/ull/Library/Python/3.9/lib/python/site-packages (from implicit) (1.12.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ull/Library/Python/3.9/lib/python/site-packages (from implicit) (4.66.2)\n",
      "Installing collected packages: implicit\n",
      "Successfully installed implicit-0.7.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-22 16:55:39--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: ‘ml-latest-small.zip’\n",
      "\n",
      "ml-latest-small.zip 100%[===================>] 955.28K   695KB/s    in 1.4s    \n",
      "\n",
      "2024-04-22 16:55:42 (695 KB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
      "\n",
      "Archive:  ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/tags.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/movies.csv  \n"
     ]
    }
   ],
   "source": [
    "# !wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "# !unzip ml-latest-small.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId,movieId,rating,timestamp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "\n",
    "with open(\"ml-latest-small/ratings.csv\", \"r\") as f:\n",
    "    print(f.readline())\n",
    "\n",
    "    for line in f:\n",
    "        uid, mid, _, _ = line.split(\",\")\n",
    "\n",
    "        rows.append(int(uid))\n",
    "        cols.append(int(mid))\n",
    "        data.append(1)\n",
    "\n",
    "rows = np.array(rows)\n",
    "cols = np.array(cols)\n",
    "data = np.array(data)\n",
    "\n",
    "csr = csr_matrix( (data, (rows, cols)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52486c1ab5284106a5d04a423a98daca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from implicit import bpr\n",
    "\n",
    "# factors default = 100\n",
    "# 이로인해 오래걸리기 때문에 현재는 10으로 설정\n",
    "model = bpr.BayesianPersonalizedRanking(factors = 10)\n",
    "model.fit(csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112556  80463  69122 134130  94959 106920  68954 122904 139385  97304]\n",
      " [  1959   2792   3361   2243   3257   2352   1269   1969   2380   2496]]\n",
      "[[4.008191  3.7780535 3.7551079 3.6089954 3.6076922 3.5593696 3.5360146\n",
      "  3.533513  3.3664985 3.3614233]\n",
      " [2.5551362 2.46272   2.4351103 2.4225845 2.363152  2.2712119 2.1340597\n",
      "  2.132045  2.129517  2.1100628]]\n"
     ]
    }
   ],
   "source": [
    "users = [2, 3]\n",
    "ids, scores = model.recommend(users, csr[users])\n",
    "print(ids) # 유저에게 추천하는 아이템의 이름\n",
    "print(scores) # 내부적으로 정해진 추천 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# low name and column name\n",
    "users = torch.from_numpy(rows)\n",
    "items = torch.from_numpy(cols)\n",
    "\n",
    "factor = 10\n",
    "item_bias = torch.randn(max(items) + 1, requires_grad=True)\n",
    "item_factor = torch.randn(max(items) + 1, factor, requires_grad=True)\n",
    "user_factor = torch.randn(max(users) + 1, factor, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train accuracy: 0.9761989712715149, cost: 9754852352.0\n",
      "epoch: 1, train accuracy: 0.9798484444618225, cost: 9760344064.0\n",
      "epoch: 2, train accuracy: 0.9829723238945007, cost: 9772918784.0\n",
      "epoch: 3, train accuracy: 0.9844896793365479, cost: 9725235200.0\n",
      "epoch: 4, train accuracy: 0.9853723049163818, cost: 9766858752.0\n",
      "epoch: 5, train accuracy: 0.9870978593826294, cost: 9756058624.0\n",
      "epoch: 6, train accuracy: 0.987752377986908, cost: 9743107072.0\n",
      "epoch: 7, train accuracy: 0.9879209995269775, cost: 9744765952.0\n",
      "epoch: 8, train accuracy: 0.9891308546066284, cost: 9740548096.0\n",
      "epoch: 9, train accuracy: 0.9891308546066284, cost: 9755918336.0\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.Adam([item_bias, item_factor, user_factor], lr=0.1)\n",
    "\n",
    "logsigmoid = torch.nn.LogSigmoid()\n",
    "lmd = 0.01\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    negative_items = torch.randint(1, max(items) + 1, (len(users),))\n",
    "\n",
    "    positive_preference = item_bias[items] + (user_factor[users] * item_factor[items]).sum(dim=1)\n",
    "    negative_preference = item_bias[negative_items] + (user_factor[users] * item_factor[negative_items]).sum(dim=1)\n",
    "\n",
    "    regularization = (item_bias ** 2).sum() + (item_factor ** 2).sum() + (user_factor ** 2).sum()\n",
    "    cost = -logsigmoid(positive_preference - negative_items).sum() + lmd * regularization\n",
    "\n",
    "    optim.zero_grad()\n",
    "    cost.backward()\n",
    "    optim.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_acc = (positive_preference > negative_preference).sum() / len(positive_preference)\n",
    "        print(f\"epoch: {epoch}, train accuracy: {train_acc.item()}, cost: {cost.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item id: 95207, score: 85.1430892944336\n",
      "item id: 99728, score: 82.00581359863281\n",
      "item id: 143367, score: 76.84660339355469\n",
      "item id: 59429, score: 76.25895690917969\n",
      "item id: 139642, score: 75.15582275390625\n",
      "item id: 103655, score: 74.18800354003906\n",
      "item id: 143365, score: 71.87625885009766\n",
      "item id: 184253, score: 71.51848602294922\n",
      "item id: 81417, score: 71.4731216430664\n",
      "item id: 110730, score: 70.53821563720703\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "   \n",
    "    outputs = 10\n",
    "    uid = 2\n",
    "    \n",
    "    scores_all = item_bias + (user_factor[uid] * item_factor).sum(dim=1) \n",
    "    scores_all = scores_all.numpy()\n",
    "\n",
    "    ids = np.argsort(scores_all)[::-1]\n",
    "    pure_ids = ids[np.isin(ids, items[users == uid], invert=True)]\n",
    "    \n",
    "    pure_ids = pure_ids[:outputs]\n",
    "    scores = scores_all[pure_ids]\n",
    "   \n",
    "    for i in range(len(pure_ids)):\n",
    "        print(f\"item id: {pure_ids[i]}, score: {scores[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
